{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b8ad74d",
   "metadata": {},
   "source": [
    "\n",
    "# üéôÔ∏è Chengyu Bites ‚Äî Unique Episode Generator & GitHub Publisher\n",
    "\n",
    "This notebook:\n",
    "1. Picks a **new (unused)** ÊàêËØ≠ (skips any already published in your repo).\n",
    "2. Generates the **podcast script** (JSON mode, robust).\n",
    "3. Creates **cover.png** and **transcript.txt**.\n",
    "4. (Optional) Generates **audio.mp3** with OpenAI TTS.\n",
    "5. Publishes in **one commit** (avoids multiple Pages builds):\n",
    "   - Uploads MP3 as a **GitHub Release** asset.\n",
    "   - Commits `_posts/YYYY-MM-DD-slug.md` + `episodes/<date>-<slug>/cover.png, transcript.txt, metadata.json`.\n",
    "\n",
    "Repo assumed: **`kohlenberg/chengyudaily`**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5169c8a7",
   "metadata": {},
   "source": [
    "## 1) Setup & Secrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "094d3af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel python: /Users/tilman/opt/anaconda3/envs/chengyudaily/bin/python\n",
      "OPENAI_API_KEY set?  True\n",
      "GITHUB_TOKEN set?    True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys, os, getpass, subprocess\n",
    "\n",
    "print(\"Kernel python:\", sys.executable)\n",
    "# Install needed packages into THIS kernel\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"-U\",\n",
    "                       \"requests\", \"pillow\", \"python-dotenv\", \"pyyaml\", \"openai>=1.40\"])\n",
    "\n",
    "# Load .env if present; otherwise prompt (values remain only in-memory for this session)\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(dotenv_path=find_dotenv(usecwd=True))\n",
    "\n",
    "def ensure_env(var):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"Enter {var}: \")\n",
    "\n",
    "for key in (\"OPENAI_API_KEY\", \"GITHUB_TOKEN\"):\n",
    "    ensure_env(key)\n",
    "\n",
    "print(\"OPENAI_API_KEY set? \", bool(os.environ.get(\"OPENAI_API_KEY\")))\n",
    "print(\"GITHUB_TOKEN set?   \", bool(os.environ.get(\"GITHUB_TOKEN\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f165b428",
   "metadata": {},
   "source": [
    "## 2) Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "952455cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- You can tweak these ----\n",
    "SHOW_NAME   = \"Chengyu Bites\"\n",
    "REPO        = \"kohlenberg/chengyudaily\"                    # owner/repo\n",
    "SITE_URL    = \"https://kohlenberg.github.io/chengyudaily\"  # public site base\n",
    "GEN_MODEL   = \"gpt-4o-mini\"          # text generation model\n",
    "TTS_MODEL   = \"gpt-4o-mini-tts\"      # tts model\n",
    "TTS_VOICE   = \"alloy\"                # tts voice\n",
    "PUBLISH_TIME_UTC = \"10:00:00 +0000\"  # front matter time\n",
    "USE_PINYIN_SLUG  = True              # safer ASCII slugs for URLs\n",
    "\n",
    "DRY_RUN = False     # True: don't touch GitHub (no release, no commit)\n",
    "DO_TTS  = True      # False: skip audio generation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878e2d2c",
   "metadata": {},
   "source": [
    "## 3) Helpers (slugify, cover image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "547dce74",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import io, re, json, unicodedata, textwrap\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "def slugify(text: str) -> str:\n",
    "    text = unicodedata.normalize(\"NFKD\", text)\n",
    "    text = re.sub(r\"[\\W_]+\", \"-\", text, flags=re.U).strip(\"-\").lower()\n",
    "    return text or \"episode\"\n",
    "\n",
    "def ensure_font(size: int):\n",
    "    for cand in [\n",
    "        \"/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf\",\n",
    "        \"/System/Library/Fonts/PingFang.ttc\",\n",
    "        \"/System/Library/Fonts/Supplemental/Arial Unicode.ttf\",\n",
    "        \"/Library/Fonts/Arial Unicode.ttf\",\n",
    "    ]:\n",
    "        try:\n",
    "            return ImageFont.truetype(cand, size)\n",
    "        except Exception:\n",
    "            pass\n",
    "    return ImageFont.load_default()\n",
    "\n",
    "def draw_cover_png(chengyu: str, pinyin: str, gloss: str) -> bytes:\n",
    "    W = H = 3000\n",
    "    bg = \"#0e1116\"\n",
    "    img = Image.new(\"RGB\", (W, H), bg)\n",
    "    d = ImageDraw.Draw(img)\n",
    "\n",
    "    font_show = ensure_font(120)\n",
    "    font_cn   = ensure_font(440)\n",
    "    font_py   = ensure_font(150)\n",
    "    font_gl   = ensure_font(90)\n",
    "\n",
    "    d.text((150, 180), SHOW_NAME, font=font_show, fill=(180,200,255))\n",
    "\n",
    "    bbox_cn = d.textbbox((0,0), chengyu, font=font_cn)\n",
    "    w_cn = bbox_cn[2]-bbox_cn[0]; h_cn = bbox_cn[3]-bbox_cn[1]\n",
    "    x_cn = (W - w_cn)//2; y_cn = (H - h_cn)//2 - 140\n",
    "    d.text((x_cn, y_cn), chengyu, font=font_cn, fill=(255,255,255))\n",
    "\n",
    "    bbox_py = d.textbbox((0,0), pinyin, font=font_py)\n",
    "    w_py = bbox_py[2]-bbox_py[0]\n",
    "    x_py = (W - w_py)//2; y_py = y_cn + h_cn + 60\n",
    "    d.text((x_py, y_py), pinyin, font=font_py, fill=(200,220,255))\n",
    "\n",
    "    gloss_wrapped = textwrap.fill(gloss, width=30)\n",
    "    d.multiline_text((150, H-520), gloss_wrapped, font=font_gl, fill=(160,180,220), spacing=12)\n",
    "\n",
    "    buf = io.BytesIO()\n",
    "    img.save(buf, \"PNG\", optimize=True)\n",
    "    return buf.getvalue()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504c43a5",
   "metadata": {},
   "source": [
    "## 4) GitHub API helpers + fetch already-used ÊàêËØ≠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3de14b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import base64, requests, re, json\n",
    "\n",
    "GITHUB_API = \"https://api.github.com\"\n",
    "\n",
    "def gh_headers():\n",
    "    token = os.environ.get(\"GITHUB_TOKEN\")\n",
    "    if not token:\n",
    "        raise RuntimeError(\"GITHUB_TOKEN not set.\")\n",
    "    return {\"Authorization\": f\"token {token}\", \"Accept\": \"application/vnd.github+json\"}\n",
    "\n",
    "def gh_create_release(repo: str, tag: str, name: str, body: str = \"\", draft=False, prerelease=False):\n",
    "    url = f\"{GITHUB_API}/repos/{repo}/releases\"\n",
    "    payload = {\"tag_name\": tag, \"name\": name, \"body\": body, \"draft\": draft, \"prerelease\": prerelease}\n",
    "    r = requests.post(url, headers=gh_headers(), json=payload, timeout=60)\n",
    "    if r.status_code not in (200,201):\n",
    "        if r.status_code == 422 and \"already_exists\" in r.text:\n",
    "            r2 = requests.get(f\"{GITHUB_API}/repos/{repo}/releases/tags/{tag}\", headers=gh_headers(), timeout=60)\n",
    "            r2.raise_for_status()\n",
    "            return r2.json()\n",
    "        raise RuntimeError(f\"Create release failed: {r.status_code} {r.text}\")\n",
    "    return r.json()\n",
    "\n",
    "def gh_upload_asset(upload_url_template: str, filename: str, data: bytes, content_type: str = \"application/octet-stream\"):\n",
    "    upload_url = upload_url_template.split(\"{\")[0] + f\"?name={filename}\"\n",
    "    headers = gh_headers(); headers[\"Content-Type\"] = content_type\n",
    "    r = requests.post(upload_url, headers=headers, data=data, timeout=300)\n",
    "    if r.status_code not in (200,201):\n",
    "        raise RuntimeError(f\"Upload asset failed: {r.status_code} {r.text}\")\n",
    "    return r.json()\n",
    "\n",
    "def fetch_used_chengyu(repo: str, branch: str = \"main\") -> set[str]:\n",
    "    \"\"\"Collect previously published chengyu from episodes/*/metadata.json and _posts/*.md.\"\"\"\n",
    "    headers = gh_headers()\n",
    "    used = set()\n",
    "\n",
    "    # A) from episodes/*/metadata.json\n",
    "    r = requests.get(f\"{GITHUB_API}/repos/{repo}/contents/episodes?ref={branch}\", headers=headers, timeout=60)\n",
    "    if r.status_code == 200:\n",
    "        for item in r.json():\n",
    "            if item.get(\"type\") == \"dir\":\n",
    "                m = requests.get(f\"{GITHUB_API}/repos/{repo}/contents/{item['path']}/metadata.json?ref={branch}\",\n",
    "                                 headers=headers, timeout=60)\n",
    "                if m.status_code == 200:\n",
    "                    try:\n",
    "                        meta = json.loads(base64.b64decode(m.json()[\"content\"]).decode(\"utf-8\"))\n",
    "                        ch = (meta.get(\"chengyu\") or \"\").strip()\n",
    "                        if ch: used.add(ch)\n",
    "                    except Exception:\n",
    "                        pass\n",
    "\n",
    "    # B) fallback: parse title from _posts/*.md\n",
    "    r = requests.get(f\"{GITHUB_API}/repos/{repo}/contents/_posts?ref={branch}\", headers=headers, timeout=60)\n",
    "    if r.status_code == 200:\n",
    "        for item in r.json():\n",
    "            if item.get(\"type\") == \"file\" and item[\"name\"].endswith(\".md\"):\n",
    "                c = requests.get(f\"{GITHUB_API}/repos/{repo}/contents/{item['path']}?ref={branch}\",\n",
    "                                 headers=headers, timeout=60)\n",
    "                if c.status_code == 200:\n",
    "                    try:\n",
    "                        text = base64.b64decode(c.json()[\"content\"]).decode(\"utf-8\", errors=\"ignore\")\n",
    "                        m = re.search(r'^title:\\s*\"(.*?)\"', text, re.M)\n",
    "                        if m:\n",
    "                            title = m.group(1)\n",
    "                            ch = title.split(\" (\")[0].strip()\n",
    "                            if ch: used.add(ch)\n",
    "                    except Exception:\n",
    "                        pass\n",
    "\n",
    "    return used\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d730fb61",
   "metadata": {},
   "source": [
    "## 5) OpenAI generation (JSON mode) + optional TTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b2266339",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "def gen_episode_with_exclusions(show_name: str, exclude: list[str]):\n",
    "    SYSTEM = (\n",
    "        \"You create short, conversational podcast episodes about Chinese ÊàêËØ≠. \"\n",
    "        \"Return ONLY a JSON object. Do not include code fences or extra text.\"\n",
    "    )\n",
    "\n",
    "    excludes_txt = \"\"\n",
    "    if exclude:\n",
    "        sample = list(exclude)[:60]  # keep prompt compact\n",
    "        excludes_txt = \"\\nDO NOT choose any of these idioms: \" + \", \".join(sample) + \". If you pick one, pick another.\\n\"\n",
    "\n",
    "    STRUCT = f\"\"\"\n",
    "Pick a well-known Chinese ÊàêËØ≠ at random and create a short, conversational episode.\n",
    "{excludes_txt}\n",
    "Follow this structure EXACTLY in the \"script\" field:\n",
    "1) Intro: Start with: \"Welcome to {show_name} ‚Äî your quick summary on Chinese ÊàêËØ≠.\" Add a one-sentence teaser about the theme. Add [break 1s].\n",
    "2) Reveal: Say \"The phrase is:\" then the idiom in CHINESE CHARACTERS, followed by the pinyin.\n",
    "3) Character breakdown: Each character with pinyin and meaning, each line ending with [break 0.5s].\n",
    "4) Full idiom again: characters + literal & figurative meaning. Add [break 1s].\n",
    "5) Origin story: 4‚Äì5 sentences. Start with \"Here‚Äôs the story behind it:\" then [break 1.5s], then the story, then [break 1.5s].\n",
    "6) Three examples: For each, give Mandarin on one line and English on the next. Put [break 1s] after each pair.\n",
    "7) Closing: Repeat the idiom in Chinese and the short English meaning; thank the listener and sign off with: \"Thanks for listening to {show_name}! See you next time for another idiom.\" End with [break 1s].\n",
    "\n",
    "Important:\n",
    "- Keep the idiom in CHINESE CHARACTERS in the script (use pinyin only where asked).\n",
    "- Use [break 0.5s], [break 1s], [break 1.5s]. No SSML.\n",
    "- Slightly slower tone via wording and breaks (‚âà90%).\n",
    "\n",
    "Return JSON with keys:\n",
    "{{\n",
    "  \"chengyu\": \"<characters>\",\n",
    "  \"pinyin\": \"<pinyin with tone marks>\",\n",
    "  \"gloss\": \"<literal + figurative meaning in one short line>\",\n",
    "  \"teaser\": \"<one-sentence teaser>\",\n",
    "  \"script\": \"<full episode script with [break] tags>\"\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "    resp = client.chat.completions.create(\n",
    "        model=GEN_MODEL,\n",
    "        temperature=0.7,\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM},\n",
    "            {\"role\": \"user\", \"content\": STRUCT},\n",
    "        ],\n",
    "    )\n",
    "    return json.loads(resp.choices[0].message.content)\n",
    "\n",
    "def gen_episode_unique(show_name: str, repo: str, branch: str = \"main\", max_tries: int = 6):\n",
    "    used = fetch_used_chengyu(repo, branch=branch)\n",
    "    used_norm = {u.strip() for u in used if u and isinstance(u, str)}\n",
    "    for i in range(max_tries):\n",
    "        data = gen_episode_with_exclusions(show_name, exclude=list(used_norm))\n",
    "        ch = (data.get(\"chengyu\") or \"\").strip()\n",
    "        if ch and ch not in used_norm:\n",
    "            return data\n",
    "        used_norm.add(ch)\n",
    "    raise RuntimeError(\"Couldn't get a new (unused) ÊàêËØ≠ after several attempts. Try again.\")\n",
    "\n",
    "def tts_mp3(script_text: str) -> bytes:\n",
    "    # Replace [break] tags with newlines for TTS\n",
    "    import re, io\n",
    "    cleaned = re.sub(r\"\\[break\\s*[0-9.]+s\\]\", \"\\n\\n\", script_text)\n",
    "    with client.audio.speech.with_streaming_response.create(\n",
    "        model=TTS_MODEL,\n",
    "        voice=TTS_VOICE,\n",
    "        input=cleaned\n",
    "    ) as response:\n",
    "        buf = io.BytesIO()\n",
    "        for chunk in response.iter_bytes():\n",
    "            buf.write(chunk)\n",
    "    return buf.getvalue()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c55b50a",
   "metadata": {},
   "source": [
    "## 6) Generate a **unique** ÊàêËØ≠ episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "702a171c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chengyu : Ëá™Áõ∏ÁüõÁõæ\n",
      "Pinyin  : z√¨ xiƒÅng m√°o d√πn\n",
      "Gloss   : to contradict oneself; to be self-contradictory\n",
      "Teaser  : Today, we explore a phrase about self-contradiction and its amusing origins.\n",
      "\n",
      "--- SCRIPT (first 1200 chars) ---\n",
      "\n",
      "Welcome to Chengyu Bites ‚Äî your quick summary on Chinese ÊàêËØ≠. Today, we explore a phrase about self-contradiction and its amusing origins. [break 1s] The phrase is: Ëá™Áõ∏ÁüõÁõæ, z√¨ xiƒÅng m√°o d√πn. [break 0.5s] Ëá™ (z√¨) - self [break 0.5s] Áõ∏ (xiƒÅng) - each other [break 0.5s] Áüõ (m√°o) - spear [break 0.5s] Áõæ (d√πn) - shield [break 0.5s] Full idiom again: Ëá™Áõ∏ÁüõÁõæ literally means 'self spear and shield' and figuratively refers to being self-contradictory. [break 1s] Here‚Äôs the story behind it: [break 1.5s] The idiom originates from an ancient tale about a seller who boasted that his spear could pierce any shield and that his shield could block any spear. A customer, hearing this, pointed out the contradiction in his claims. The story humorously highlights how one can contradict themselves without realizing it. [break 1.5s] Example 1: ‰ªñÊÄªÊòØËØ¥Ë¶ÅÂáèËÇ•Ôºå‰ΩÜÊØèÂ§©ÈÉΩÂêÉÂø´È§ê„ÄÇ [break 1s] He always says he wants to lose weight, but eats fast food every day. [break 1s] Example 2: Â•πÊä±ÊÄ®Â∑•‰ΩúÂ§™Á¥ØÔºåÂç¥‰ªé‰∏çËØ∑ÂÅá„ÄÇ [break 1s] She complains that work is too tiring, yet never takes a day off. [break 1s] Example 3: ËøôÊú¨‰π¶ËÆ≤ÁöÑÁêÜËÆ∫Ëá™Áõ∏ÁüõÁõæ„ÄÇ [break 1s] The theories discussed in this book are self-contradictory. [break 1s] So, to sum up, Ëá™Áõ∏ÁüõÁõæ means to contradict onesel...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ep = gen_episode_unique(SHOW_NAME, repo=REPO, branch=\"main\")\n",
    "print(\"Chengyu :\", ep[\"chengyu\"])\n",
    "print(\"Pinyin  :\", ep[\"pinyin\"])\n",
    "print(\"Gloss   :\", ep[\"gloss\"])\n",
    "print(\"Teaser  :\", ep[\"teaser\"])\n",
    "\n",
    "print(\"\\n--- SCRIPT (first 1200 chars) ---\\n\")\n",
    "print(ep[\"script\"][:1200] + (\"...\" if len(ep[\"script\"])>1200 else \"\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6aa0171",
   "metadata": {},
   "source": [
    "## 7) (Optional) Edit before publishing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fe4141d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ëá™Áõ∏ÁüõÁõæ | z√¨ xiƒÅng m√°o d√πn\n",
      "to contradict oneself; to be self-contradictory\n",
      "\n",
      "Preview script start:\n",
      " Welcome to Chengyu Bites ‚Äî your quick summary on Chinese ÊàêËØ≠. Today, we explore a phrase about self-contradiction and its amusing origins. [break 1s] The phrase is: Ëá™Áõ∏ÁüõÁõæ, z√¨ xiƒÅng m√°o d√πn. [break 0.5s] Ëá™ (z√¨) - self [break 0.5s] Áõ∏ (xiƒÅng) - each other [break 0.5s] Áüõ (m√°o) - spear [break 0.5s] Áõæ (d√πn) - shield [break 0.5s] Full idiom again: Ëá™Áõ∏ÁüõÁõæ literally means 'self spear and shield' and figuratively refers to being self-contradictory. [break 1s] Here‚Äôs the story behind it: [break 1.5s] The idiom originates from an ancient tale about a seller who boasted that his spear could pierce any shield a\n"
     ]
    }
   ],
   "source": [
    "\n",
    "chengyu = ep[\"chengyu\"]\n",
    "pinyin  = ep[\"pinyin\"]\n",
    "gloss   = ep[\"gloss\"]\n",
    "teaser  = ep[\"teaser\"]\n",
    "script  = ep[\"script\"]\n",
    "\n",
    "# Example manual tweak:\n",
    "# teaser = \"A quick bite about perspective.\"\n",
    "\n",
    "print(chengyu, \"|\", pinyin)\n",
    "print(gloss)\n",
    "print(\"\\nPreview script start:\\n\", script[:600])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2c35c0",
   "metadata": {},
   "source": [
    "## 8) Build local assets (cover, transcript, optional TTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "989c3769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio generated: /Users/tilman/github3/chengyudaily/build/2025-08-21-zi-xia-ng-ma-o-du-n/audio.mp3\n",
      "Built assets in: /Users/tilman/github3/chengyudaily/build/2025-08-21-zi-xia-ng-ma-o-du-n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "today = datetime.date.today()\n",
    "date_str = today.strftime(\"%Y-%m-%d\")\n",
    "slug_base = pinyin if USE_PINYIN_SLUG else chengyu\n",
    "slug = slugify(slug_base)\n",
    "folder = f\"{date_str}-{slug}\"\n",
    "\n",
    "ep_dir = Path(\"build\") / folder\n",
    "ep_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# cover\n",
    "cover_png = draw_cover_png(chengyu, pinyin, gloss)\n",
    "( ep_dir / \"cover.png\").write_bytes(cover_png)\n",
    "\n",
    "# transcript\n",
    "( ep_dir / \"transcript.txt\").write_text(script, encoding=\"utf-8\")\n",
    "\n",
    "# metadata\n",
    "metadata = {\n",
    "    \"show\": SHOW_NAME,\n",
    "    \"chengyu\": chengyu,\n",
    "    \"pinyin\": pinyin,\n",
    "    \"gloss\": gloss,\n",
    "    \"teaser\": teaser,\n",
    "    \"pubDate\": today.isoformat()\n",
    "}\n",
    "( ep_dir / \"metadata.json\").write_text(json.dumps(metadata, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "audio_mp3 = b\"\"\n",
    "if DO_TTS:\n",
    "    try:\n",
    "        audio_mp3 = tts_mp3(script)\n",
    "        ( ep_dir / \"audio.mp3\").write_bytes(audio_mp3)\n",
    "        print(\"Audio generated:\", (ep_dir/\"audio.mp3\").resolve())\n",
    "    except Exception as e:\n",
    "        print(\"TTS failed:\", e)\n",
    "else:\n",
    "    print(\"Skipping TTS (DO_TTS=False)\")\n",
    "\n",
    "print(\"Built assets in:\", ep_dir.resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c4d981",
   "metadata": {},
   "source": [
    "## 9) Publish: GitHub Release (MP3) + one commit push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5f5e6a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded asset: https://github.com/kohlenberg/chengyudaily/releases/download/v20250821-zi-xia-ng-ma-o-du-n/2025-08-21-zi-xia-ng-ma-o-du-n.mp3\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/var/folders/wn/z035vl9x1_q0_8dhkvn9n24h0000gn/T/chengyudaily_j3bfy9ui/episodes/2025-08-20-bu-ke-si-yi/audio.mp3'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[54]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     22\u001b[39m audio_bytes = asset.get(\u001b[33m\"\u001b[39m\u001b[33msize\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(audio_mp3))\n\u001b[32m     23\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mUploaded asset:\u001b[39m\u001b[33m\"\u001b[39m, audio_url)\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[43m(\u001b[49m\u001b[43mdest_ep\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio.mp3\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_mp3\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# Use site-hosted audio for best mobile compatibility\u001b[39;00m\n\u001b[32m     26\u001b[39m audio_url = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m/episodes/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfolder\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/audio.mp3\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/chengyudaily/lib/python3.11/pathlib.py:1067\u001b[39m, in \u001b[36mPath.write_bytes\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m   1065\u001b[39m \u001b[38;5;66;03m# type-check for the buffer interface before truncating the file\u001b[39;00m\n\u001b[32m   1066\u001b[39m view = \u001b[38;5;28mmemoryview\u001b[39m(data)\n\u001b[32m-> \u001b[39m\u001b[32m1067\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mwb\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m   1068\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m f.write(view)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/chengyudaily/lib/python3.11/pathlib.py:1044\u001b[39m, in \u001b[36mPath.open\u001b[39m\u001b[34m(self, mode, buffering, encoding, errors, newline)\u001b[39m\n\u001b[32m   1042\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1043\u001b[39m     encoding = io.text_encoding(encoding)\n\u001b[32m-> \u001b[39m\u001b[32m1044\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m io.open(\u001b[38;5;28mself\u001b[39m, mode, buffering, encoding, errors, newline)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/var/folders/wn/z035vl9x1_q0_8dhkvn9n24h0000gn/T/chengyudaily_j3bfy9ui/episodes/2025-08-20-bu-ke-si-yi/audio.mp3'"
     ]
    }
   ],
   "source": [
    "\n",
    "import tempfile, shutil, subprocess\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "def run(cmd, cwd=None, hide_token=False):\n",
    "    display = \" \".join([\"***\" if hide_token and \"@\" in str(x) else str(x) for x in cmd])\n",
    "    print(\"+\", display)\n",
    "    subprocess.check_call(cmd, cwd=cwd)\n",
    "\n",
    "if DRY_RUN:\n",
    "    print(\"DRY_RUN=True ‚Äî skipping GitHub release & push.\")\n",
    "else:\n",
    "    # 1) Create release + upload MP3\n",
    "    audio_url = \"\"\n",
    "    audio_bytes = 0\n",
    "    if DO_TTS and audio_mp3:\n",
    "        tag  = f\"v{today.strftime('%Y%m%d')}-{slug}\"\n",
    "        name = f\"{chengyu} ({pinyin})\"\n",
    "        rel  = gh_create_release(REPO, tag=tag, name=name, body=f\"Episode: {chengyu}\")\n",
    "        asset = gh_upload_asset(rel[\"upload_url\"], filename=f\"{folder}.mp3\", data=audio_mp3, content_type=\"audio/mpeg\")\n",
    "        audio_url = asset[\"browser_download_url\"]\n",
    "        audio_bytes = asset.get(\"size\", len(audio_mp3))\n",
    "        print(\"Uploaded asset:\", audio_url)\n",
    "        (dest_ep / \"audio.mp3\").write_bytes(audio_mp3)\n",
    "        # Use site-hosted audio for best mobile compatibility\n",
    "        audio_url = f\"/episodes/{folder}/audio.mp3\"\n",
    "        audio_bytes = len(audio_mp3)\n",
    "    else:\n",
    "        print(\"No audio to upload (TTS disabled or failed). You can upload manually later and set audio_url in the post.\")\n",
    "\n",
    "    # 2) Prepare post markdown (no /chengyudaily prefix to avoid double baseurl)\n",
    "    cover_path_for_web = f\"/episodes/{folder}/cover.png\"\n",
    "\n",
    "    fm = {\n",
    "         \"layout\": \"post\",\n",
    "         \"title\": f\"{chengyu} ({pinyin})\",\n",
    "         \"date\": f\"{date_str} {PUBLISH_TIME_UTC}\",\n",
    "         \"description\": gloss,\n",
    "         \"cover_image\": f\"/episodes/{folder}/cover.png\",\n",
    "         \"audio_url\": audio_url,           # now local to your Pages site\n",
    "         \"audio_bytes\": audio_bytes\n",
    "\n",
    "        \n",
    "    }\n",
    "    if audio_url:\n",
    "        fm[\"audio_url\"] = audio_url\n",
    "        fm[\"audio_bytes\"] = audio_bytes\n",
    "\n",
    "    body_md = (\n",
    "        script.replace(\"[break 0.5s]\", \"\")\n",
    "              .replace(\"[break 1s]\", \"\")\n",
    "              .replace(\"[break 1.5s]\", \"\")\n",
    "              .strip()\n",
    "    )\n",
    "    front = (\n",
    "        \"---\\n\"\n",
    "        + \"\\n\".join(\n",
    "            f\"{k}: {json.dumps(v, ensure_ascii=False) if not isinstance(v, (int,float)) else v}\"\n",
    "            for k, v in fm.items()\n",
    "        )\n",
    "        + \"\\n---\\n\\n\"\n",
    "    )\n",
    "    post_md = front + body_md + \"\\n\"\n",
    "    post_relpath = f\"_posts/{date_str}-{slug}.md\"\n",
    "\n",
    "    # 3) Clone repo, write files, single commit, push\n",
    "    tmp = tempfile.mkdtemp(prefix=\"chengyudaily_\")\n",
    "    try:\n",
    "        import os\n",
    "        token = os.environ.get(\"GITHUB_TOKEN\")\n",
    "        if not token:\n",
    "            raise RuntimeError(\"GITHUB_TOKEN not set\")\n",
    "        repo_url = f\"https://{token}@github.com/{REPO}.git\"\n",
    "\n",
    "        run([\"git\", \"clone\", \"--depth\", \"1\", repo_url, tmp], hide_token=True)\n",
    "        run([\"git\", \"config\", \"user.name\", \"Chengyu Publisher Bot\"], cwd=tmp)\n",
    "        run([\"git\", \"config\", \"user.email\", \"actions@users.noreply.github.com\"], cwd=tmp)\n",
    "\n",
    "        dest_ep = Path(tmp) / \"episodes\" / folder\n",
    "        dest_ep.mkdir(parents=True, exist_ok=True)\n",
    "        (dest_ep / \"cover.png\").write_bytes(cover_png)\n",
    "        (dest_ep / \"transcript.txt\").write_text(script, encoding=\"utf-8\")\n",
    "        (dest_ep / \"metadata.json\").write_text(json.dumps({\n",
    "            \"show\": SHOW_NAME,\n",
    "            \"chengyu\": chengyu,\n",
    "            \"pinyin\": pinyin,\n",
    "            \"gloss\": gloss,\n",
    "            \"teaser\": teaser,\n",
    "            \"pubDate\": today.isoformat(),\n",
    "            \"audio_url\": audio_url,\n",
    "            \"audio_bytes\": audio_bytes\n",
    "        }, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "        posts_dir = Path(tmp) / \"_posts\"\n",
    "        posts_dir.mkdir(exist_ok=True)\n",
    "        (posts_dir / f\"{date_str}-{slug}.md\").write_text(post_md, encoding=\"utf-8\")\n",
    "\n",
    "        run([\"git\", \"add\", \".\"], cwd=tmp)\n",
    "        run([\"git\", \"commit\", \"-m\", f\"Add episode {folder}\"], cwd=tmp)\n",
    "        run([\"git\", \"push\", \"origin\", \"main\"], cwd=tmp, hide_token=True)\n",
    "\n",
    "        print(\"\\n‚úî Pushed one commit. Your Pages workflow should build & deploy.\")\n",
    "        print(\"Episode page (after deploy):\")\n",
    "        print(f\"{SITE_URL}/\" + f\"{today.strftime('%Y/%m/%d')}/{slug}.html\")\n",
    "        if audio_url:\n",
    "            print(\"Audio URL:\", audio_url)\n",
    "    finally:\n",
    "        shutil.rmtree(tmp, ignore_errors=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb33d80",
   "metadata": {},
   "source": [
    "## 10) Done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57dbd1e",
   "metadata": {},
   "source": [
    "\n",
    "**Notes**\n",
    "- Ensure your repo has a **Pages workflow** (we recommended `.github/workflows/pages.yml`) and Pages **Source = GitHub Actions**.\n",
    "- The feed (`podcast.xml`) can be built by your workflow (via `build_feed.py`) so no extra commit is needed.\n",
    "- To avoid duplicate base URLs in the feed image, posts use `cover_image: \"/episodes/.../cover.png\"`.\n",
    "- Slugs default to **pinyin** (`USE_PINYIN_SLUG=True`) for ASCII-safe URLs.\n",
    "\n",
    "Re-run this notebook anytime for a new, unique episode. üéâ\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chengyudaily",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
